[
  {
    "book_name": "custom-database.html",
    "abstract": "介绍如何自定义Hypothesis数据库，包括实现SQLiteExampleDatabase类及其save、fetch、delete方法，并说明move方法的默认行为及重写方式。",
    "content": "# Write a custom Hypothesis database\n\nTo define your own `ExampleDatabase` class, implement the `save()`, `fetch()`, and `delete()` methods.\n\nFor example, here’s a simple database class that uses sqlite as the backing data store:\n\n```python\nimport sqlite3\nfrom collections.abc import Iterable\nfrom hypothesis.database import ExampleDatabase\n\nclass SQLiteExampleDatabase(ExampleDatabase):\n    def __init__(self, db_path: str):\n        self.conn = sqlite3.connect(db_path)\n        self.conn.execute(\n            \"\"\"\n            CREATE TABLE examples (\n                key BLOB,\n                value BLOB,\n                UNIQUE (key, value)\n            )\n            \"\"\"\n        )\n\n    def save(self, key: bytes, value: bytes) -> None:\n        self.conn.execute(\n            \"INSERT OR IGNORE INTO examples VALUES (?, ?)\",\n            (key, value),\n        )\n\n    def fetch(self, key: bytes) -> Iterable[bytes]:\n        cursor = self.conn.execute(\"SELECT value FROM examples WHERE key = ?\", (key,))\n        yield from [value[0] for value in cursor.fetchall()]\n\n    def delete(self, key: bytes, value: bytes) -> None:\n        self.conn.execute(\n            \"DELETE FROM examples WHERE key = ? AND value = ?\",\n            (key, value),\n        )\n```\n\nDatabase classes are not required to implement `move()`. The default implementation of a move is a `delete()` of the value in the old key, followed by a `save()` of the value in the new key. You can override `move()` to override this behavior, if for instance the backing store offers a more efficient move implementation."
  },
  {
    "book_name": "custom-database.html",
    "abstract": "说明如何在自定义数据库类中支持变更监听，包括调用_broadcast_change()方法，并提及_start_listening()和_stop_listening()方法用于管理监听操作。",
    "content": "\n\n## Change listening\n\nTo support change listening in a database class, you should call `_broadcast_change()` whenever a value is saved, deleted, or moved in the backing database store. How you track this depends on the details of the database class. For instance, in `DirectoryBasedExampleDatabase`, Hypothesis installs a filesystem monitor via watchdog in order to broadcast change events.\n\nTwo useful related methods are `_start_listening()` and `_stop_listening()`, which a database class can override to know when to start or stop expensive listening operations. See documentation for details."
  },
  {
    "book_name": "custom-strategies.html",
    "abstract": "介绍如何编写自定义策略，包括编写辅助函数和使用@composite装饰器创建新策略。",
    "content": "Custom strategies\n=================\n\nThis page describes how to write a custom strategy, for when the built-in strategies don’t quite fit your needs.\n\nWriting helper functions\n------------------------\n\nSometimes you might find it useful to write helper functions, to more concisely express a common pattern for your project. For example, it’s much easier to write (and read!) `response=json()` than to have the whole implementation inline:\n\n```python\ndef json(*, finite_only=True):\n    \"\"\"Helper function to describe JSON objects, with optional inf and nan.\"\"\"\n    numbers = st.floats(allow_infinity=not finite_only, allow_nan=not finite_only)\n    return st.recursive(\n        st.none() | st.booleans() | st.integers() | numbers | st.text(),\n        extend=lambda xs: st.lists(xs) | st.dictionaries(st.text(), xs),\n    )\n```\n\nWriting your own strategy\n-------------------------\n\nIf a strategy in Hypothesis doesn’t match what you need, you can write your own strategy.\n\nFor instance, suppose we want to generate a list of floats which sum to 1. We might start implementing this by generating lists of integers between 0 and 1 with `lists(floats(0, 1))`. But now we’re a bit stuck, and can’t go any further with the standard strategies.\n\nOne way to define a new strategy is using the `@composite` decorator. `@composite` lets you define a new strategy that uses arbitrary Python code. For instance, to implement the above:\n\n```python\nfrom hypothesis import strategies as st\n\n@st.composite\ndef sums_to_one(draw):\n    l = draw(st.lists(st.floats(0, 1)))\n    return [f / sum(l) for f in l]\n```\n\n`@composite` passes a `draw` function to the decorated function as its first argument."
  },
  {
    "book_name": "custom-strategies.html",
    "abstract": "介绍Hypothesis库中@composite装饰器的基本用法，通过sums_to_one示例展示如何创建自定义策略，并演示其在属性测试中的应用。",
    "content": " `draw` is used to draw a random value from another strategy. We return from `sums_to_one` a value of the form we wanted to generate; in this case, a list that sums to one.\n\nLet’s see this new strategy in action:\n\n```python\nimport pytest\nfrom hypothesis import given, strategies as st\n\n@st.composite\ndef sums_to_one(draw):\n    lst = draw(st.lists(st.floats(0.001, 1), min_size=1))\n    return [f / sum(lst) for f in lst]\n\n@given(sums_to_one())\ndef test(lst):\n    # ignore floating point errors\n    assert sum(lst) == pytest.approx(1)\n```\n\n> **Note**\n>\n> Just like all other strategies, we called `sums_to_one` before passing it to `@given`. `@composite` should be thought of as turning its decorated function into a function which returns a strategy when called. This is actually the same as existing strategies in Hypothesis; `integers()` is really a function, which returns a strategy for integers when called."
  },
  {
    "book_name": "custom-strategies.html",
    "abstract": "介绍如何在使用 @composite 装饰器的函数中添加普通参数和仅关键字参数，并通过 sums_to_n 示例展示其用法。",
    "content": "\n\nCombining `@composite` with parameters\n--------------------------------------\n\nYou can add parameters to functions decorated with `@composite`, including keyword-only arguments. These work as you would normally expect.\n\nFor instance, suppose we wanted to generalize our `sums_to_one` function to `sums_to_n`. We can add a parameter `n`:\n\n```python\nimport pytest\nfrom hypothesis import assume, given, strategies as st\n\n@st.composite\ndef sums_to_n(draw, n=1):  # <-- changed\n    lst = draw(st.lists(st.floats(0, 1), min_size=1))\n    assume(sum(lst) > 0)\n    return [f / sum(lst) * n for f in lst]  # <-- changed\n\n@given(sums_to_n(10))\ndef test(lst):\n    assert sum(lst) == pytest.approx(10)\n```"
  },
  {
    "book_name": "custom-strategies.html",
    "abstract": "展示了如何将 `n` 设为仅限关键字参数，并介绍了使用 `@composite` 装饰器生成相互依赖的值（如有序整数对）的方法。",
    "content": "\n\nAnd we could just as easily have made `n` a keyword-only argument instead:\n\n```python\nimport pytest\nfrom hypothesis import assume, given, strategies as st\n\n@st.composite\ndef sums_to_n(draw, *, n=1):  # <-- changed\n    lst = draw(st.lists(st.floats(0, 1), min_size=1))\n    assume(sum(lst) > 0)\n    return [f / sum(lst) * n for f in lst]\n\n@given(sums_to_n(n=10))  # <-- changed\ndef test(lst):\n    assert sum(lst) == pytest.approx(10)\n```\n\nDependent generation with `@composite`\n--------------------------------------\n\nAnother scenario where `@composite` is useful is when generating a value that depends on a value from another strategy. For instance, suppose we wanted to generate two integers `n1` and `n2` with `n1 <= n2`. We can do this using `@composite`:\n\n```python\n@st.composite\ndef ordered_pairs(draw):\n    n1 = draw(st.integers())\n    n2 = draw(st.integers(min_value=n1))\n    return (n1, n2)\n\n@given(ordered_pairs())\ndef test_pairs_are_ordered(pair):\n    n1, n2 = pair\n    assert n1 <= n2\n```\n\n> **Note**\n>\n> We could also have written this particular strategy as `st.tuples(st.integers(), st.integers()).map("
  },
  {
    "book_name": "custom-strategies.html",
    "abstract": "介绍了在测试中混合数据生成与测试代码的方法，对比了`@composite`和`data()`的使用场景，并指出了`data()`的缺点。",
    "content": "sorted)` (see Adapting strategies). Some prefer this inline approach, while others prefer defining well-named helper functions with `@composite`. Our suggestion is simply that you prioritize ease of understanding when choosing which to use.\n\nMixing data generation and test code\n------------------------------------\n\nWhen using `@composite`, you have to finish generating the entire input before running your test. But maybe you don’t want to generate all of the input until you’re sure some initial test assertions have passed. Or maybe you have some complicated control flow which makes it necessary to generate something in the middle of the test.\n\n`data()` lets you do this. It’s similar to `@composite`, except it lets you mix test code and generation code.\n\n> **Note**\n>\n> The downside of this power is that `data()` is incompatible with `@example`, and that Hypothesis cannot print a nice representation of values generated from `data()` when reporting failing examples, because the draws are spread out. Where possible, prefer `@composite` to `data()`.\n\nFor instance, here’s how we would write our earlier `@composite` example using `data()`:"
  },
  {
    "book_name": "detect-hypothesis-tests.html",
    "abstract": "介绍了两种动态检测 Hypothesis 测试函数的方法：一是使用 `is_hypothesis_test()` 工具函数，该方法对普通测试和基于状态机的测试均有效；二是利用 pytest 插件自动添加的 `hypothesis` 标记进行检测。",
    "content": "# Detect Hypothesis tests\n\nHow to dynamically determine whether a test function has been defined with Hypothesis.\n\n## Via `is_hypothesis_test`\n\nThe most straightforward way is to use `is_hypothesis_test()`:\n\n```python\nfrom hypothesis import is_hypothesis_test\n\n@given(st.integers())\ndef f(n): ...\n\nassert is_hypothesis_test(f)\n```\n\nThis works for stateful tests as well:\n\n```python\nfrom hypothesis import is_hypothesis_test\nfrom hypothesis.stateful import RuleBasedStateMachine\n\nclass MyStateMachine(RuleBasedStateMachine): ...\n\nassert is_hypothesis_test(MyStateMachine.TestCase().runTest)\n```\n\n## Via pytest\n\nIf you’re working with pytest, the Hypothesis pytest plugin automatically adds the `@pytest.mark.hypothesis` mark to all Hypothesis tests. You can use `node.get_closest_marker(\"hypothesis\")` or similar methods to detect the existence of this mark."
  },
  {
    "book_name": "domain.html",
    "abstract": "Hypothesis区分策略的“域”（domain）和“分布”（distribution），并认为用户应负责选择域，而库本身负责选择分布。文章建议使用最通用的策略以覆盖所有潜在的边界情况，并指出仅在性能问题出现时才应限制输入大小。",
    "content": "Domain and distribution\n\nNote\n\nThis page is primarily for users who may be familiar with other property-based testing libraries, and who expect control over the distribution of inputs in Hypothesis, via e.g. a `scale` parameter for size or a `frequency` parameter for relative probabilities.\n\nHypothesis makes a distinction between the domain of a strategy, and the distribution of a strategy.\n\nThe domain is the set of inputs that should be possible to generate. For instance, in `lists(integers())`, the domain is lists of integers. For other strategies, particularly those that use `@composite` or `assume()` in their definition, the domain might be more complex.\n\nThe distribution is the probability with which different elements in the domain should be generated. For `lists(integers())`, should Hypothesis generate many small lists? Large lists? More positive or more negative numbers? etc.\n\nHypothesis takes a philosophical stance that while users may be responsible for selecting the domain, the property-based testing library—not the user—should be responsible for selecting the distribution. As an intentional design choice, Hypothesis therefore lets you control the domain of inputs to your test, but not the distribution.\n\nHow should I choose a domain for my test?\n\nWe recommend using the most-general strategy for your test, so that it can in principle generate any edge case for which the test should pass. Limiting the size of generated inputs, and especially limiting the variety of inputs, can all too easily exclude the bug-triggering values from consideration - and be the difference between a test which finds the bug, or fails to do so.\n\nSometimes size limits are necessary for performance reasons, but we recommend limiting your strategies only after you’ve seen substantial slowdowns without limits. Far better to find bugs slowly, than not find them at all - and you can manage performance with the `phases` or `max_examples` settings rather than weakening the test."
  },
  {
    "book_name": "domain.html",
    "abstract": "A brief, incomplete thought or rhetorical question.",
    "content": "\n\nWhy not"
  },
  {
    "book_name": "example-count.html",
    "abstract": "Hypothesis运行测试的次数通常为max_examples次，但存在例外情况：当搜索空间耗尽时会少于该次数；当因assume()或.filter()导致重试时会多于该次数。",
    "content": "How many times will Hypothesis run my test?\n\nThis is a trickier question than you might expect."
  },
  {
    "book_name": "example-count.html",
    "abstract": "Hypothesis测试运行次数通常为max_examples次，但存在三种例外情况：搜索空间耗尽、因assume()/filter()导致重试、或发现失败用例。",
    "content": " The short answer is “exactly max_examples times”, with the following exceptions:\n\n- Less than max_examples times, if Hypothesis exhausts the search space early.\n- More than max_examples times, if Hypothesis retries some examples because either:\n- Either less or more than max_examples times, if Hypothesis finds a failing example.\n\nRead on for details."
  },
  {
    "book_name": "example-count.html",
    "abstract": "介绍了 Hypothesis 在搜索空间耗尽时的行为，即当没有更多示例可尝试时，会提前停止生成。并通过整数范围策略的示例说明了这一点。",
    "content": "\n\n## Search space exhaustion\n\nIf Hypothesis detects that there are no more examples left to try, it may stop generating examples before it hits max_examples. For example:\n\n```python\nfrom hypothesis import given, strategies as st\n\ncalls = 0\n\n@given(st.integers(0, 19))\ndef test_function(n):\n    global calls\n    calls += 1\n\ntest_function()\nassert calls == 20\n```\n\nThis runs `test_function` 20 times, not 100, since there are only 20 unique integers to try.\n\nThe search space tracking in Hypothesis is good, but not perfect. We treat this more as a bonus than something to strive for."
  },
  {
    "book_name": "example-count.html",
    "abstract": "(part 1/2) 介绍了 `assume()` 和 `.filter()` 的工作方式，它们在条件不满足时会重试生成示例且不计入 `max_examples` 限制，并比较了两者的效率差异。",
    "content": "\n\n## `assume()` and `.filter()`\n\nIf an example fails to satisfy an `assume()` or `.filter()` condition, Hypothesis will retry generating that example and will not count it towards the `max_examples` limit. For instance:\n\n```python\nfrom hypothesis import assume, given, strategies as st\n\n@given(st.integers())\ndef test_function(n):\n    assume(n % 2 == 0)\n```\n\nwill run roughly 200 times, since half of the examples are discarded from the `assume()`.\n\nNote that while failing an `assume()` triggers an immediate retry of the entire example, Hypothesis will try several times in the same example to satisfy a `.filter()` condition. This makes expressing the same condition using `.filter()` more efficient than `assume()`."
  },
  {
    "book_name": "example-count.html",
    "abstract": "(part 2/2) 说明了内置策略可能隐式使用 `assume()` 或 `.filter()`，并介绍了因示例过大或测试失败而触发的重试和额外执行行为，包括健康检查、收缩和解释阶段。",
    "content": "\n\nAlso note that even if your code does not explicitly use `assume()` or `.filter()`, a builtin strategy may still use them and cause retries. We try to directly satisfy conditions where possible instead of relying on rejection sampling, so this should be relatively uncommon.\n\n## Examples which are too large\n\nFor performance reasons, Hypothesis places an internal limit on the size of a single example. If an example exceeds this size limit, we will retry generating it and will not count it towards the `max_examples` limit. (And if we see too many of these large examples, we will raise `HealthCheck.data_too_large`, unless suppressed with `settings.suppress_health_check`).\n\nThe specific value of this size limit is an undocumented implementation detail. The majority of Hypothesis tests do not come close to hitting it.\n\n## Failing examples\n\nIf Hypothesis finds a failing example, it stops generation early, and may call the test function additional times during the `Phase.shrink` and `Phase.explain` phases. Sometimes, Hypothesis determines that the initial failing example was already as simple as possible, in which case `Phase.shrink` will not result in additional test executions (but `Phase.explain` might).\n\nRegardless of whether Hypothesis runs the test during the shrinking and explain phases, it will always run the minimal failing example one additional time to check for flakiness. For instance, the following trivial test runs with `n=0` twice, even though it only uses the `Phase.generate` phase:\n\nThe first execution finds the initial failure with `n=0`, and the second execution replays `n=0` to ensure the failure is not flaky."
  },
  {
    "book_name": "external-fuzzers.html",
    "abstract": "介绍了将Hypothesis与外部模糊测试工具（如python-afl或atheris）结合使用的场景和动机，并引出了`fuzz_one_input()`方法作为核心接口。",
    "content": "Use Hypothesis with an external fuzzer\n=====================================\n\nSometimes you might want to point a traditional fuzzer like python-afl or Google’s atheris at your code, to get coverage-guided exploration of native C extensions. The associated tooling is often much less mature than property-based testing libraries though, so you might want to use Hypothesis strategies to describe your input data, and our world-class shrinking and observability tools to wrangle the results. That’s exactly what this how-to guide is about!"
  },
  {
    "book_name": "external-fuzzers.html",
    "abstract": "介绍 Hypothesis 的 fuzz_one_input() 方法，用于将 Hypothesis 测试作为传统模糊测试目标，并说明其绕过标准测试生命周期的特性。",
    "content": "\n\nNote\n----\n\nIf you already have Hypothesis tests and want to fuzz them, or are targeting pure Python code, we strongly recommend the purpose-built HypoFuzz. This page is about writing traditional ‘fuzz harnesses’ with an external fuzzer, using parts of Hypothesis.\n\nIn order to support this workflow, Hypothesis exposes the `fuzz_one_input()` method. `fuzz_one_input()` takes a bytestring, parses it into a test case, and executes the corresponding test once. This means you can treat each of your Hypothesis tests as a traditional fuzz target, by pointing the fuzzer at `fuzz_one_input()`.\n\nFor example:\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.integers())\ndef test_ints(n):\n    pass\n\n# this parses the bytestring into a test case using st.integers(),\n# and then executes `test_ints` once.\ntest_ints.hypothesis.fuzz_one_input(b\"\\x00\" * 50)\n```\n\nNote that `fuzz_one_input()` bypasses the standard test lifecycle. In a standard test run, Hypothesis is responsible for managing the lifecycle of a test, for example by moving between each `Phase`. In contrast, `fuzz_one_input()` executes one test case, independent of this lifecycle.\n\nSee the documentation of `fuzz_one_input()` for details of how it interacts with other features of Hypothesis, such as `@settings`."
  },
  {
    "book_name": "external-fuzzers.html",
    "abstract": "展示了如何结合Atheris和Hypothesis进行模糊测试，通过Hypothesis生成有效的JSON对象并用`json.dumps`进行测试。",
    "content": "\n\nWorked example: using Atheris\n-----------------------------\n\nHere is an example that uses `fuzz_one_input()` with the Atheris coverage-guided fuzzer (which is built on top of libFuzzer):\n\n```python\nimport json\nimport sys\nimport atheris\nfrom hypothesis import given, strategies as st\n\n@given(\n    st.recursive(\n        st.none() | st.booleans() | st.integers() | st.floats() | st.text(),\n        lambda j: st.lists(j) | st.dictionaries(st.text(), j),\n    )\n)\ndef test_json_dumps_valid_json(value):\n    json.dumps(value)\n\natheris.Setup(sys.argv, test_json_dumps_valid_json.hypothesis.fuzz_one_input)\natheris.Fuzz()"
  },
  {
    "book_name": "external-fuzzers.html",
    "abstract": "指出仅用Atheris原生接口生成有效JSON更困难，并建议使用`atheris.instrument_all`或`atheris.instrument_imports`来增加覆盖率检测。",
    "content": "\n```\n\nGenerating valid JSON objects based only on Atheris’ `FuzzDataProvider` interface would be considerably more difficult.\n\nYou may also want to use `atheris.instrument_all` or `atheris.instrument_imports` in order to add coverage instrumentation to Atheris. See the Atheris documentation for full details."
  },
  {
    "book_name": "flaky.html",
    "abstract": "介绍了“Flaky failures”（不稳定失败）的概念，即测试在重试时可能从失败变为通过，这种非确定性的测试被称为 flaky test。",
    "content": "Flaky failures\n\nHave you ever had a test fail, and then you re-run it, only for the test to magically pass? That is a flaky test. A flaky test is one which might behave differently when called again. You can think of it as a test which is not deterministic."
  },
  {
    "book_name": "flaky.html",
    "abstract": "解释了任何测试都可能存在不稳定性，而 Hypothesis 由于会多次运行测试，因此特别容易暴露出这种不稳定行为。",
    "content": "\n\nAny test can be flaky, but because Hypothesis runs your test many times, Hypothesis tests are particularly likely to uncover flaky behavior."
  },
  {
    "book_name": "integrations.html",
    "abstract": "Hypothesis Ghostwriter 工具介绍 (part 1)",
    "content": "Integrations Reference\n======================\n\nReference for Hypothesis features with a defined interface, but no code API.\n\nGhostwriter\n-----------\n\nWriting tests with Hypothesis frees you from the tedium of deciding on and writing out specific inputs to test. Now, the `hypothesis.extra.ghostwriter` module can write your test functions for you too!"
  },
  {
    "book_name": "integrations.html",
    "abstract": "Introduction to property-based testing with ghostwritten tests and command-line interface examples.",
    "content": "\n\nThe idea is to provide an easy way to start property-based testing, and a seamless transition to more complex test code—because ghostwritten tests are source code that you could have written for yourself.\n\nSo just pick a function you’d like tested, and feed it to one of the functions below. They follow imports, use but do not require type annotations, and generally do their best to write you a useful test. You can also use our command-line interface:\n\n```console\n$ hypothesis write --help\nUsage: hypothesis write [OPTIONS] FUNC...\n\n`hypothesis write` writes property-based tests for you!\n\nType annotations are helpful but not required for our advanced introspection and templating logic. Try running the examples below to see how it works:\n\nhypothesis write gzip\nhypothesis write numpy.matmul\nhypothesis write pandas.from_dummies\nhypothesis write re.compile --except re.error\nhypothesis write --equivalent ast.literal_eval eval\nhypothesis write --roundtrip json.dumps json.loads\nhypothesis write --style=unittest --idempotent sorted\nhypothesis write --binary-op operator.add\n\nOptions:\n  --roundtrip              start by testing write/read or encode/decode!\n  --equivalent             very useful when optimising or refactoring code\n  --errors-equivalent      --equivalent, but also allows consistent errors\n  --idempotent             check that f(x) == f(f(x))\n  --binary-op              associativity, commutativity, identity element\n  --style [pytest|unittest] pytest-style function, or unittest-style method?\n  -e, --except OBJ_NAME    dotted name of exception(s) to ignore\n  --annotate / --no-annotate force ghostwritten tests to be type-"
  },
  {
    "book_name": "internals.html",
    "abstract": "Hypothesis internals introduction and warning",
    "content": "Hypothesis internals\n\nWarning\n\nThis page documents internal Hypothesis interfaces. Some are fairly stable, while others are still experimental. In either case, they are not subject to our standard deprecation policy, and we might make breaking changes in minor or patch releases.\n\nThis page is intended for people building tools, libraries, or research on top of Hypothesis. If that includes you, ple"
  },
  {
    "book_name": "internals.html",
    "abstract": "介绍 Hypothesis 的 PrimitiveProvider 接口及其 lifetime 属性，说明其在测试函数或测试用例级别的生命周期管理。",
    "content": "ase get in touch! We’d love to hear what you’re doing, or explore more stable ways to support your use-case.\n\nAlternative backends\n\nSee also\n\nSee also the user-facing Alternative backends for Hypothesis documentation.\n\n- class hypothesis.internal.conjecture.providers.PrimitiveProvider(conjecturedata, /)[source]\n\nPrimitiveProvider is the implementation interface of a Hypothesis backend. A PrimitiveProvider is required to implement the following five draw_* methods:\n\nEach strategy in Hypothesis generates values by drawing a series of choices from these five methods. By overriding them, a PrimitiveProvider can control the distribution of inputs generated by Hypothesis.\n\nFor example, hypothesis-crosshair implements a PrimitiveProvider which uses an SMT solver to generate inputs that uncover new branches.\n\nOnce you implement a PrimitiveProvider, you can make it available for use through AVAILABLE_PROVIDERS.\n\n- lifetime = 'test_function'\n\nThe lifetime of a PrimitiveProvider instance. Either test_function or test_case.\n\nIf test_function (the default), a single provider instance will be instantiated and used for the entirety of each test function (i.e., roughly one provider per @given annotation). This can be useful for tracking state over the entirety of a test function.\n\nIf test_case, a new provider instance will be instantiated and used for each input Hypothesis generates.\n\nThe conjecturedata argument to PrimitiveProvider.__init__ will be None for a lifetime of test_function, and an instance of ConjectureData for a lifetime of test_case.\n\nThird-party providers likely want to set"
  },
  {
    "book_name": "internals.html",
    "abstract": "描述 PrimitiveProvider 的 avoid_realization 和 add_observability_callback 属性，以及 draw_boolean 和 draw_integer 方法的参数与行为。",
    "content": " a lifetime of test_function.\n\n- avoid_realization = False\n\nSolver-based backends such as hypothesis-crosshair use symbolic values which record operations performed on them in order to discover new paths. If avoid_realization is set to True, hypothesis will avoid interacting with symbolic choices returned by the provider in any way that would force the solver to narrow the range of possible values for that symbolic.\n\nSetting this to True disables some hypothesis features and optimizations. Only set this to True if it is necessary for your backend.\n\n- add_observability_callback = False\n\nwill never be called by Hypothesis.\n\nThe opt-in behavior of observability is because enabling observability might increase runtime or memory usage.\n\n- abstract draw_boolean(p=0.5)[source]\n\nDraw a boolean choice.\n\nParameters:\n  p (float) – The probability of returning True. Between 0 and 1 inclusive. Except for 0 and 1, the value of p is a hint provided by Hypothesis, and may be ignored by the backend. If 0, the provider must return False. If 1, the provider must return True.\n\n- abstract draw_integer(min_value=None, max_value=None, *, weights=None, shrink_towards=0)[source]\n\nDraw an integer choice.\n\nParameters:\n  min_value (int | None) – (Inclusive) lower bound on the integer value. If None, there is no lower bound.\n  max_value (int | None) – (Inclusive) upper bound on the integer value. If None, there is no upper bound.\n  weights (dict[int, float] | None) – Maps keys in the range [min_value, max_value] to the probability of returning that key.\n  shrink_towards (int) – The integer to shrink towards. This is not used during generation and can be ignored by backends."
  },
  {
    "book_name": "internals.html",
    "abstract": "描述 PrimitiveProvider 的 draw_float 和 draw_string 方法的参数，以及 per_test_case_context_manager 和 realize 方法的作用。",
    "content": "\n\n- abstract draw_float(*, min_value=-inf, max_value=inf, allow_nan=True, smallest_nonzero_magnitude)[source]\n\nDraw a float choice.\n\nParameters:\n  min_value (float) – (Inclusive) lower bound on the float value.\n  max_value (float) – (Inclusive) upper bound on the float value.\n  allow_nan (bool) – If False, it is invalid to return math.nan.\n  smallest_nonzero_magnitude (float) – The smallest allowed nonzero magnitude. draw_float should not return a float f if abs(f) < smallest_nonzero_magnitude.\n\n- abstract draw_string(intervals, *, min_size=0, max_size=10000000000)[source]\n\nDraw a string choice.\n\nParameters:\n  intervals (IntervalSet) – The set of codepoints to sample from.\n  min_size (int) – (Inclusive) lower bound on the string length.\n  max_size (int) – (Inclusive) upper bound on the string length.\n\n- per_test_case_context_manager()[source]\n\nReturns a context manager which will be entered each time Hypothesis starts generating and executing one test case, and exited when that test case finishes generating and executing, including if any exception is thrown.\n\nIn the lifecycle of a Hypothesis test, this is called before generating strategy values for each test case. This is just before any custom executor is called.\n\nEven if not returning a custom context manager, PrimitiveProvider subclasses are welcome to override this method to know when Hypothesis starts and ends the execution of a single test case.\n\n- realize(value, *, for_failure=False)[source]\n\nCalled whenever hypothesis requires a concrete (non-symbolic) value from a potentially symbolic value. Hypothesis will not check that value is symbolic before calling realize, so you should handle the case where value is non-symbolic.\n\nThe returned value should be non-symbolic. If you cannot provide a value, raise BackendCannotProceed with a value of \"discard_test_case\"."
  },
  {
    "book_name": "internals.html",
    "abstract": "描述 PrimitiveProvider 的 replay_choices、observe_test_case、observe_information_messages 和 on_observation 方法的功能，涉及失败用例处理、观测数据收集与信息消息传递。",
    "content": "\n\nIf for_failure is True, the value is associated with a failing example. In this case, the backend should spend substantially more effort when attempting to realize the value, since it is important to avoid discarding failing examples. Backends may still raise BackendCannotProceed when for_failure is True, if realization is truly impossible or if realization takes significantly longer than expected (say, 5 minutes).\n\n- replay_choices(choices)[source]\n\nCalled when Hypothesis has discovered a choice sequence which the provider may wish to enqueue to replay under its own instrumentation when we next ask to generate a test case, rather than generating one from scratch.\n\nThis is used to e.g. warm-start hypothesis-crosshair with a corpus of high-code-coverage inputs discovered by HypoFuzz.\n\n- observe_test_case()[source]\n\nCalled at the end of the test case when observability is enabled.\n\nThe return value should be a non-symbolic json-encodable dictionary, and will be included in observations as observation[\"metadata\"][\"backend\"].\n\n- observe_information_messages(*, lifetime)[source]\n\nCalled at the end of each test case and again at end of the test function.\n\nReturn an iterable of {type: info/alert/error, title: str, content: str | dict} dictionaries to be delivered as individual information messages. Hypothesis adds the run_start timestamp and property name for you.\n\n- on_observation(observation)[source]\n\nCalled at the end of each test case which uses this provider, with the same observation[\"type\"] == \"test_case\" observation that is passed to other callbacks added via add_observability_callback. This method is not called with observation[\"type\"] in {\"info\""
  },
  {
    "book_name": "introduction.html",
    "abstract": "Hypothesis简介、安装方法及一个简单的整数测试示例。",
    "content": "Introduction to Hypothesis\n===========================\n\nThis page introduces two fundamental parts of Hypothesis (`@given` and strategies) and shows how to test a selection sort implementation using Hypothesis.\n\nInstall Hypothesis\n------------------\n\nFirst, let’s install Hypothesis:\n\n```bash\npip install hypothesis\n```\n\nDefining a simple test\n----------------------\n\nHypothesis tests are defined using two things: `@given` and a strategy, which is passed to `@given`. Here’s a simple example:\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.integers())\ndef test_is_integer(n):\n    assert isinstance(n, int)\n```\n\nAdding the `@given` decorator turns this function into a Hypothesis test. Passing `integers()` to `@given` says that Hypothesis should generate random integers for the argument `n` when testing."
  },
  {
    "book_name": "introduction.html",
    "abstract": "介绍了如何使用 Hypothesis 库进行属性测试，包括测试一个整数检查函数和一个选择排序算法。通过 `@given` 装饰器和策略（如 `st.integers()` 和 `st.lists()`），Hypothesis 能自动生成测试用例。",
    "content": "\n\nWe can run this test by calling it:\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.integers())\ndef test_is_integer(n):\n    print(f\"called with {n}\")\n    assert isinstance(n, int)\n\ntest_is_integer()\n```\n\nNote that we don’t pass anything for `n`; Hypothesis handles generating that value for us. The resulting output looks like this:\n\n```\ncalled with 0\ncalled with -18588\ncalled with -672780074\ncalled with 32616\n...\n```\n\nTesting a sorting algorithm\n--------------------------\n\nSuppose we have implemented a simple selection sort and want to make sure it’s correct. We can write the following test by combining the `integers()` and `lists()` strategies:\n\n```python\n@given(st.lists(st.integers()))\ndef test_sort_correct(lst):\n    print(f\"called with {lst}\")\n    assert selection_sort(lst.copy()) == sorted(lst)\n\ntest_sort_correct()\n```\n\nWhen running `test_sort_correct`, Hypothesis uses the `lists(integers())` strategy to generate random lists of integers. Feel free to run `python example.py` to get an idea of the kinds of lists Hypothesis generates (and to convince yourself that this test passes)."
  },
  {
    "book_name": "introduction.html",
    "abstract": "介绍了如何使用 Hypothesis 库的策略组合（`|` 操作符）来生成包含整数或浮点数的列表以测试排序函数，并指出由于 `nan` 值导致排序行为未定义，因此需要通过 `floats(allow_nan=False)` 来排除 `nan`。",
    "content": "\n\nAdding floats to our test\n-------------------------\n\nThis test is a good start. But `selection_sort` should be able to sort lists with floats, too. If we wanted to generate lists of either integers or floats, we can change our strategy:\n\n```python\n# changes to example.py\n@given(st.lists(st.integers() | st.floats()))\ndef test_sort_correct(lst):\n    pass\n```\n\nThe pipe operator `|` takes two strategies and returns a new strategy which generates values from either of its strategies. So the strategy `integers() | floats()` can generate either an integer or a float.\n\n> **Note**  \n> `strategy1 | strategy2` is equivalent to `st.one_of(strategy1, strategy2)`.\n\nPreventing `floats()` from generating `nan`\n------------------------------------------\n\nEven though `test_sort_correct` passed when we used lists of integers, it actually fails now that we’ve added floats! If you run `python example.py`, you’ll likely (but not always; this is random testing, after all) find that Hypothesis reports a counterexample to `test_sort_correct`. For me, that counterexample is `[1.0, nan, 0]`. It might be different for you.\n\nThe issue is that sorting in the presence of `nan` is not well defined. As a result, we may decide that we don’t want to generate them while testing. We can pass `floats(allow_nan=False)` to tell Hypothesis not to generate `nan`:\n\n```python\n# changes to example.py\n@given(st.lists(st.integers() | st.floats(allow_nan=False)))\ndef test_sort_correct(lst):\n    pass\n```\n\nAnd now this test passes without issues."
  },
  {
    "book_name": "introduction.html",
    "abstract": "说明了如何使用 Hypothesis 为测试函数提供多个参数，包括位置参数和关键字参数，并介绍了运行 Hypothesis 测试的几种方式。",
    "content": "\n\n> **Note**  \n> You can use the `.example()` method to get an idea of the kinds of things a strategy will generate:\n>\n> ```python\n> >>> st.lists(st.integers() | st.floats(allow_nan=False)).example()\n> [-5.969063e-08, 15283673678, 18717, -inf]\n> ```\n>\n> Note that `.example()` is intended for interactive use only (i.e., in a REPL). It is not intended to be used inside tests.\n\nTests with multiple arguments\n-----------------------------\n\nIf we wanted to pass multiple arguments to a test, we can do this by passing multiple strategies to `@given`:\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.integers(), st.lists(st.floats()))\ndef test_multiple_arguments(n, lst):\n    assert isinstance(n, int)\n    assert isinstance(lst, list)\n    for f in lst:\n        assert isinstance(f, float)\n```\n\nKeyword arguments\n-----------------\n\nWe can also pass strategies using keyword arguments:\n\n```python\n@given(lst=st.lists(st.floats()), n=st.integers())  # <-- changed\ndef test_multiple_arguments(n, lst):\n    pass\n```\n\nNote that even though we changed the order the parameters to `@given` appear, we also explicitly told it which parameters to pass to by using keyword arguments, so the meaning of the test hasn’t changed.\n\nIn general, you can think of positional and keyword arguments to `@given` as being forwarded to the test arguments.\n\nRunning Hypothesis tests\n------------------------\n\nThere are a few ways to run a Hypothesis test:\n\n- Explicitly call it, like `test_is_integer()`, as we’ve seen. Hypothesis tests are just normal functions, except `@given` handles generating and passing values for the function arguments.\n- Let a test runner such as `pytest` pick up on it (as long as the function name star"
  },
  {
    "book_name": "introduction.html",
    "abstract": "讨论了何时使用 Hypothesis 和基于属性的测试，建议寻找往返属性、替换参数化测试，并列举了其他类型的可测试属性，如优化实现的等价性、金融交易的平衡性等。",
    "content": "ts with `test_`).\n\nConcretely, when running a Hypothesis test, Hypothesis will:\n\n- Generate 100 random inputs,\n- Run the body of the function for each input, and\n- Report any exceptions that get raised.\n\n> **Note**  \n> The number of examples can be controlled with the `max_examples` setting. The default is 100.\n\nWhen to use Hypothesis and property-based testing\n------------------------------------------------\n\nProperty-based testing is a powerful addition to unit testing. It is not always a replacement.\n\nIf you’re having trouble coming up with a property in your code to test, we recommend trying the following:\n\n- Look for round-trip properties: encode/decode, serialize/deserialize, etc. These property-based tests tend to be both powerful and easy to write.\n- Look for `@pytest.mark.parametrize` in your existing tests. This is sometimes a good hint you can replace the parametrization with a strategy. For instance, `@pytest.mark.parametrize(\"n\", range(0, 100))` could be replaced by `@given(st.integers(0, 100 - 1))`.\n- Simply call your code with random inputs (of the correct shape) from Hypothesis! You might be surprised how often this finds crashes. This can be especially valuable for projects with a single entrypoint interface to a lot of underlying code.\n\nOther examples of properties include:\n\n- An optimized implementation is equivalent to a slower, but clearly correct, implementation.\n- A sequence of transactions in a financial system always “balances”; money never gets lost.\n- The derivative of a polynomial of order `n` has order `n - 1`.\n- A type-checker, linter, formatter, or compiler does not crash when called on syntactically valid code."
  },
  {
    "book_name": "quickstart.html",
    "abstract": "Hypothesis快速入门指南的第一部分，介绍了安装方法、编写第一个测试用例以及`@given`装饰器的基本用法。",
    "content": "# Quickstart\n\nThis is a lightning introduction to the most important features of Hypothesis; enough to get you started writing tests. The tutorial introduces these features (and more) in greater detail.\n\n## Install Hypothesis\n\n```bash\npip install hypothesis\n```\n\n## Write your first test\n\nCreate a new file called `example.py`, containing a simple test:\n\n```python\n# contents of example.py\nfrom hypothesis import given, strategies as st\n\n@given(st.integers())\ndef test_integers(n):\n    print(f\"called with {n}\")\n    assert isinstance(n, int)\n\ntest_integers()\n```\n\n`@given` is the standard entrypoint to Hypothesis. It takes a strategy, which describes the type of inputs you want the decorated function to accept. When we call `test_integers`, Hypothesis will generate random integers (because we used the `integers()` strategy) and pass them as `n`. Let’s see that in action now by running `python example.py`:\n\n```\ncalled with 0\ncalled with -18588\ncalled with -672780074\ncalled with 32616\n...\n```\n\nWe just called `test_integers()`, without passing a value for `n`, because Hypothesis generates random values of `n` for us."
  },
  {
    "book_name": "quickstart.html",
    "abstract": "介绍了Hypothesis测试的基本概念，包括其默认生成100个随机输入、可被pytest或unittest识别为常规Python函数，并通过一个会失败的整数测试示例展示了其使用方法和错误输出。",
    "content": "\n\n> **Note**  \n> By default, Hypothesis generates 100 random inputs. You can control this with the `max_examples` setting.\n\n## Running in a test suite\n\nA Hypothesis test is still a regular Python function, which means pytest or unittest will pick it up and run it in all the normal ways.\n\n```python\n# contents of example.py\nfrom hypothesis import given, strategies as st\n\n@given(st.integers(0, 200))\ndef test_integers(n):\n    assert n < 50\n```\n\nThis test will clearly fail, which can be confirmed by running `pytest example.py`:\n\n```\n$ pytest example.py\n...\n@given(st.integers())\ndef test_integers(n):\n>   assert n < 50\nE   assert 50 < 50\nE   Falsifying example: test_integers(\nE       n=50,\nE   )"
  },
  {
    "book_name": "quickstart.html",
    "abstract": "说明了`@given`装饰器可以接受多个参数，并给出了一个同时使用整数和文本策略的测试函数示例。",
    "content": "\n```\n\n## Arguments to `@given`\n\nYou can pass multiple arguments to `@given`:\n\n```python\n@given(st.integers(), st.text())\ndef test_integers(n, s):\n    assert isinstance(n, int)"
  },
  {
    "book_name": "replaying-failures.html",
    "abstract": "介绍了 Hypothesis 测试中重放失败用例的重要性及主要方法，包括自动保存到本地数据库和手动重放。",
    "content": "Replaying failed tests\n======================\n\nReplaying failures found by your Hypothesis tests is almost as important as finding failures in the first place. Hypothesis therefore contains several ways to replay failures: they are automatically saved to (and replayed from) a local `ExampleDatabase`, and can be manually replayed via `@example` or `@reproduce_failure`."
  },
  {
    "book_name": "replaying-failures.html",
    "abstract": "文章剩余部分仅包含一个标题“The Hypothesis database”。",
    "content": "\n\nThe Hypothesis database\n----"
  },
  {
    "book_name": "settings.html",
    "abstract": "介绍了如何使用 @settings 装饰器来配置单个 Hypothesis 测试的行为，包括生成示例数量、重放失败示例和详细级别等，并说明了如何通过设置配置整个测试套件。",
    "content": "Configuring test settings\n=========================\n\nThis page discusses how to configure the behavior of a single Hypothesis test, or of an entire test suite.\n\nConfiguring a single test\n-------------------------\n\nHypothesis lets you configure the default behavior of a test using the `@settings` decorator. You can use settings to configure how many examples Hypothesis generates, how Hypothesis replays failing examples, and the verbosity level of the test, among others.\n\nUsing `@settings` on a single test looks like this:\n\n```python\nfrom hypothesis import given, settings, strategies as st\n\n@given(st.integers())\n@settings(max_examples=200)\ndef runs_200_times_instead_of_100(n):\n    pass\n```\n\nYou can put `@settings` either before or after `@given`. Both are equivalent.\n\nChanging the number of examples\n-------------------------------\n\nIf you have a test which is very expensive or very cheap to run, you can change the number of examples (inputs) Hypothesis generates with the `max_examples` setting:\n\nThe default is 100 examples.\n\n> **Note**\n>\n> See *How many times will Hypothesis run my test?* for details on how `max_examples` interacts with other parts of Hypothesis.\n\nOther settings options\n----------------------\n\nHere are a few of the more commonly used setting values:\n\n- `settings.phases` controls which phases of Hypothesis run, like replaying from the database or generating new inputs.\n- `settings.database` controls how and if Hypothesis replays failing examples.\n- `settings.verbosity` can print debug information.\n- `settings.derandomize` makes Hypothesis deterministic. (*Two kinds of testing* discusses when and why you might want that).\n\n> **Note**\n>\n> See the *settings reference* for a full list of possible settings.\n\nChanging settings across your test suite\n----------------------------------------\n\nIn addition to configuring individual test functions with `@settings`, you can configure test behavior across your test suite using a settings profile. This might be usef"
  },
  {
    "book_name": "settings.html",
    "abstract": "Hypothesis库的设置配置文件（settings profiles）功能介绍，包括如何注册、加载配置文件，以及通过环境变量动态选择配置。",
    "content": "ul for creating a development settings profile which runs fewer examples, or a settings profile in CI which connects to a separate database.\n\nTo create a settings profile, use `register_profile()`:\n\n```python\nfrom hypothesis import HealthCheck, settings\n\nsettings.register_profile(\"fast\", max_examples=10)\n```\n\nYou can place this code in any file which gets loaded before your tests get run. This includes an `__init__.py` file in the test directory or any of the test files themselves. If using pytest, the standard location to place this code is in a `conftest.py` file (though an `__init__.py` or test file will also work).\n\nNote that registering a new profile will not affect tests until it is loaded with `load_profile()`:\n\n```python\nfrom hypothesis import HealthCheck, settings\n\nsettings.register_profile(\"fast\", max_examples=10)\n# any tests executed before loading this profile will still use the\n# default active profile of 100 examples.\nsettings.load_profile(\"fast\")\n# any tests executed after this point will use the active fast\n# profile of 10 examples.\n```\n\nThere is no limit to the number of settings profiles you can create. Hypothesis creates a profile called `\"default\"`, which is active by default. You can also explicitly make it active at any time using `settings.load_profile(\"default\")`, if for instance you wanted to revert a custom profile you had previously loaded.\n\nLoading profiles from environment variables\n-------------------------------------------\n\nUsing an environment variable to load a settings profile is a useful trick for choosing a settings profile depending on the environment:\n\n```python\n>>> import os\n>>> from hypothesis import settings, Verbosity\n>>> settings.register_profile(\"long\", max_examples=1000)\n>>> settings.register_profile(\"fast\", max_examples=10)\n>>> settings.register_profile(\"debug\", max_examples=10, verbosity=Verbosity.verbose)\n>>> settings.load_profile(os.getenv(\"HYPOTHESIS_PROFILE\", \"default\"))\n```\n\nIf using pytest, you can also easily se"
  },
  {
    "book_name": "settings.html",
    "abstract": "在pytest中通过命令行参数选择Hypothesis的设置配置文件。",
    "content": "lect the active profile with `--hypothesis-profile`:\n\n```bash\n$ pytest --hypothesis-profile fast\n```\n\nSee the Hypothesis pytest plugin."
  },
  {
    "book_name": "stateful.html",
    "abstract": "介绍了 Hypothesis 库中状态测试（Stateful tests）的基本概念，将其与标准的 `@given` 测试进行对比，并引出了基于规则的状态机（Rule-based state machines）作为处理复杂测试场景的方法。",
    "content": "Stateful tests\n\nNote\n\nSee also [How not to Die Hard with Hypothesis](https://hypothesis.works/articles/how-not-to-die-hard-with-hypothesis/) and [An Introduction to Rule-Based Stateful Testing](https://hypothesis.works/articles/rule-based-stateful-testing/).\n\nWith `@given`, your tests are still something that you mostly write yourself, with Hypothesis providing some data. With Hypothesis’s stateful testing, Hypothesis instead tries to generate not just data but entire tests. You specify a number of primitive actions that can be combined together, and then Hypothesis will try to find sequences of those actions that result in a failure.\n\nYou may not need stateful tests\n\nThe basic idea of stateful testing is to make Hypothesis choose actions as well as values for your test, and state machines are a great declarative way to do just that.\n\nFor simpler cases though, you might not need them at all—a standard test with `@given` might be enough, since you can use `data()` in branches or loops. In fact, that’s how the state machine explorer works internally. For more complex workloads though, where a higher level API comes into its own, keep reading!\n\nRule-based state machines\n\nA state machine is very similar to a normal `@given` based test in that it takes values drawn from strategies and passes them to a user defined test function, which may use assertions to check the system’s behavior. The key difference is that where `@given` based tests must be independent, rules can be chained together—a single test run may involve multiple rule invocations, which may interact in various ways."
  },
  {
    "book_name": "stateful.html",
    "abstract": "介绍 Hypothesis 中 Bundles 的概念、用途及其与实例变量的对比。",
    "content": "\n\nRules can take normal strategies as arguments, but normal strategies, with the exception of `runner()` and `data()`, cannot take into account the current state of the machine. This is where bundles come in.\n\nA rule can, in place of a normal strategy, take a `Bundle`. A `hypothesis.stateful.Bundle` is a named collection of generated values that can be reused by other operations in the test. They are populated with the results of rules, and may be used as arguments to rules, allowing data to flow from one rule to another, and rules to work on the results of previous computations or actions.\n\nSpecifically, a rule that specifies `target=a_bundle` will cause its return value to be added to that bundle. A rule that specifies `an_argument=a_bundle` as a strategy will draw a value from that bundle. A rule can also specify that an argument chooses a value from a bundle and removes that value by using `consumes()` as in `an_argument=consumes(a_bundle)`.\n\nNote\n\nThere is some overlap between what you can do with Bundles and what you can do with instance variables. Both represent state that rules can manipulate. If you do not need to draw values that depend on the machine’s state, you can simply use instance variables. If you do need to draw values that depend on the machine’s state, Bundles provide a fairly straightforward way to do this. If you need rules that draw values that depend on the machine’s state in some more complicated way, you will have to abandon bundles. You can use `runner()` and `.flatmap()` to access the instance from a rule: the strategy `runner().flatmap(lambda self: sampled_from(self.a_list))` will draw from the instance variable `a_list`. If you need something more complicated still, you can use `data()` to draw data from the instance (or anywhere else) based on logic in the rule."
  },
  {
    "book_name": "stateful.html",
    "abstract": "Hypothesis规则状态机示例：通过规则状态机测试Hypothesis示例数据库实现，将其与内存中的字典模型进行行为对比。",
    "content": "\n\nThe following rule based state machine example is a simplified version of a test for Hypothesis’s example database implementation. An example database maps keys to sets of values, and in this test we compare one implementation of it to a simplified in memory model of its behaviour, which just stores the same values in a Python `dict`."
  },
  {
    "book_name": "stateful.html",
    "abstract": "介绍了一个用于比较真实数据库与内存模型行为的测试类 DatabaseComparison，其通过 Hypothesis 的状态机和 Bundle 机制生成并操作键值对。",
    "content": " The test then runs operations against both the real database and the in-memory representation of it and looks for discrepancies in their behaviour.\n\n```python\nimport shutil\nimport tempfile\nfrom collections import defaultdict\nimport hypothesis.strategies as st\nfrom hypothesis.database import DirectoryBasedExampleDatabase\nfrom hypothesis.stateful import Bundle, RuleBasedStateMachine, rule\n\nclass DatabaseComparison(RuleBasedStateMachine):\n    def __init__(self):\n        super().__init__()\n        self.tempd = tempfile.mkdtemp()\n        self.database = DirectoryBasedExampleDatabase(self.tempd)\n        self.model = defaultdict(set)\n\n    keys = Bundle(\"keys\")\n    values = Bundle(\"values\")\n\n    @rule(target=keys, k=st.binary())\n    def add_key(self, k):\n        return k\n\n    @rule(target=values, v=st.binary())\n    def add_value(self, v):\n        return v\n\n    @rule(k=keys, v=values)\n    def save(self, k, v):\n        self.model[k].add(v)\n        self.database.save(k, v)\n\n    @rule(k=keys, v=values)\n    def delete(self, k, v):\n        self.model[k].discard(v)\n        self.database.delete(k, v)\n\n    @rule(k=keys)\n    def values_agree(self, k):\n        assert set(self.database.fetch(k)) == self.model[k]\n\n    def teardown(self):\n        shutil.rmtree(self.tempd)\n\nTestDBComparison = DatabaseComparison.TestCase\n```\n\nIn this we declare two bundles—one for keys, and one for values. We have two trivial rules which just populate th"
  },
  {
    "book_name": "stateful.html",
    "abstract": "详细说明了 DatabaseComparison 状态机中非平凡规则（save, delete, values_agree）的功能，并解释了使用 Bundle 的优势在于促进操作复用相同的键和值。同时展示了如何将其集成到测试套件中以及失败时的输出示例。",
    "content": "em with data (`k` and `v`), and three non-trivial rules: `save` saves a value under a key and `delete` removes a value from a key, in both cases also updating the model of what should be in the database. `values_agree` then checks that the contents of the database agrees with the model for a particular key.\n\nNote\n\nWhile this could have been simplified by not using bundles, generating keys and values directly in the `save` and `delete` rules, using bundles encourages Hypothesis to choose the same keys and values for multiple operations. The bundle operations establish a “universe” of keys and values that are used in the rules.\n\nWe can now integrate this into our test suite by getting a unittest `TestCase` from it:\n\n```python\nTestTrees = DatabaseComparison.TestCase\n# Or just run with pytest's unittest support\nif __name__ == \"__main__\":\n    unittest.main()\n```\n\nThis test currently passes, but if we comment out the line where we call `self.model[k].discard(v)`, we would see the following output when run under pytest:\n\n```\nAssertionError: assert set() == {b''}\n------------ Hypothesis ------------\nstate = DatabaseComparison()\nvar1 = state.add_key(k=b'')\nvar2 = state.add_value(v=var1)\nstate.save(k=var1, v=var2)\nstate.delete(k=var1, v=var2)\nstate.values_agree(k=var1)\nstate.teardown()\n```\n\nNote how it’s printed out a very short program that will demonstrate the problem. The output from a rule based state machine should generally be pretty close to Python code—if you have custom `repr` implementations that don’t return valid Python then it might not be, but most of the time you should just be able to copy and paste the code into a test to reproduce it."
  },
  {
    "book_name": "stateful.html",
    "abstract": "(part 1/2) 介绍了如何通过设置 TestCase 的 settings 对象来控制测试行为，并详细阐述了规则（Rules）的定义、限制和使用方法，以及初始化（Initializes）作为一种特殊规则的作用和典型应用场景。",
    "content": "\n\nYou can control the detailed behaviour with a settings object on the `TestCase` (this is a normal hypothesis settings object using the defaults at the time the `TestCase` class was first referenced). For example if you wanted to run fewer examples with larger programs you could change the settings to:\n\n```python\nDatabaseComparison.TestCase.settings = settings(\n    max_examples=50, stateful_step_count=100\n)\n```\n\nWhich doubles the number of steps each program runs and halves the number of test cases that will be run.\n\nRules\n\nAs said earlier, rules are the most common feature used in `RuleBasedStateMachine`. They are defined by applying the `rule()` decorator on a function. Note that `RuleBasedStateMachine` must have at least one rule defined and that a single function cannot be used to define multiple rules (this is to avoid having multiple rules doing the same things). Due to the stateful execution method, rules generally cannot take arguments from other sources such as fixtures or `pytest.mark.parametrize`—consider providing them via a strategy such as `sampled_from()` instead.\n\nInitializes\n\nInitializes are a special case of rules, which are guaranteed to be run exactly once before any normal rule is called. Note if multiple initialize rules are defined, they will all be called but in any order, and that order will vary from run to run.\n\nInitializes are typically useful to populate bundles:\n\n```python\nimport hypothesis.strategies as st\nfrom hypothesis.stateful import Bundle, RuleBasedStateMachine, initialize, rule\n\nname_strategy = st.text(min_size=1).filter(lambda x: \"/\" not in x)\n\nclass NumberModifier(RuleBasedStateMachine):\n    folders = Bundle(\"folders\")\n    files = Bundle(\"files\")\n\n    @initialize(target=folders)\n    def init_folders(self):\n        return \"/\"\n\n    @rule(target=folders, parent=folders, name=name_strategy)\n    def create_folder(self, parent, name):\n        return f\"{parent}/{n"
  },
  {
    "book_name": "strategies.html",
    "abstract": "Hypothesis策略参考文档的引言和基本原语部分，介绍了策略的概念、用法以及`none()`、`nothing()`和`just(value)`三个基础策略。",
    "content": "Strategies Reference\n====================\n\nStrategies are the way Hypothesis describes the values for `@given` to generate. For instance, passing the strategy `st.lists(st.integers(), min_size=1)` to `@given` tells Hypothesis to generate lists of integers with at least one element.\n\nThis reference page lists all of Hypothesis’ first-party functions which return a strategy. There are also many provided by third-party libraries. Note that we often say “strategy” when we mean “function returning a strategy”; it’s usually clear from context which one we mean.\n\nStrategies can be passed to other strategies as arguments, combined using combinator strategies, or modified using `.filter()`, `.map()`, or `.flatmap()`.\n\nPrimitives\n----------\n\n- `hypothesis.strategies.none()` [source]_\n  Return a strategy which only generates `None`.\n  Examples from this strategy do not shrink (because there is only one)."
  },
  {
    "book_name": "strategies.html",
    "abstract": "Hypothesis策略库中用于生成固定值或无值的策略，以及整数生成策略的介绍。",
    "content": "\n\n- `hypothesis.strategies.nothing()` [source]_\n  This strategy never successfully draws a value and will always reject on an attempt to draw.\n  Examples from this strategy do not shrink (because there are none).\n\n- `hypothesis.strategies.just(value)` [source]_\n  Return a strategy which only generates `value`.\n\n  .. note::\n     `value` is not copied. Be wary of using mutable values.\n     If `value` is the result of a callable, you can use `builds(callable)` instead of `just(callable())` to get a fresh value each time.\n\n  Examples from this strategy do not shrink (because there is only one).\n\nNumeric\n-------\n\nSee also\n~~~~~~~~\n\nSee also the separate sections for Numpy strategies, Pandas strategies, and Array API strategies.\n\n- `hypothesis.strategies.integers(min_value=None, max_value=None)` [source]_\n  Returns a strategy which generates integers.\n  If `min_value` is not None then all values will be >= `min_value`. If `max_value` is not None then all values will be <= `max_value`.\n  Examples from this strategy will shrink towards zero, and negative values will also shrink towards positive (i.e. -n may be replaced by +n)."
  },
  {
    "book_name": "strategies.html",
    "abstract": "(part 1/2) 介绍了 hypothesis.strategies.floats 策略的参数、行为和约束，包括值域限制、特殊值（NaN, infinity, subnormal）的处理、精度宽度以及区间端点的排除规则。",
    "content": "\n\n- `hypothesis.strategies.floats(min_value=None, max_value=None, *, allow_nan=None, allow_infinity=None, allow_subnormal=None, width=64, exclude_min=False, exclude_max=False)` [source]_\n  Returns a strategy which generates floats.\n\n  If `min_value` is not None, all values will be >= `min_value` (or > `min_value` if `exclude_min`). If `max_value` is not None, all values will be <= `max_value` (or < `max_value` if `exclude_max`).\n\n  If `min_value` or `max_value` is not None, it is an error to enable `allow_nan`. If both `min_value` and `max_value` are not None, it is an error to enable `allow_infinity`. If inferred values range does not include subnormal values, it is an error to enable `allow_subnormal`.\n\n  Where not explicitly ruled out by the bounds, subnormals, infinities, and NaNs are possible values generated by this strategy.\n\n  The `width` argument specifies the maximum number of bits of precision required to represent the generated float. Valid values are 16, 32, or 64. Passing `width=32` will still use the builtin 64-bit `float` class, but always for values which can be exactly represented as a 32-bit float.\n\n  The `exclude_min` and `exclude_max` argument can be used to generate numbers from open or half-open intervals, by excluding the respective endpoints. Excluding either signed zero will also exclude the other. Attempting to exclude an endpoint which is `None` will raise an error; use `allow_infinity=False` to generate finite floats. You can however use e.g. `min_value=-math.inf, exclude_min=True` to exclude only one infinite endpoint.\n\n  Examples from this strategy have a complicated and hard to explain shrinking behaviour, but it tries to improve “human readability”. Finite numbers will be preferred to infinity and infinity will be preferred to NaN."
  },
  {
    "book_name": "strategies.html",
    "abstract": "文档片段：hypothesis库中complex_numbers策略的函数签名。",
    "content": "\n\n- `hypothesis.strategies.complex_numbers(*, min_magnitude=0, max_magnitude=None, allow_infinity=None, allow_nan=None, allow_subnormal=True, width=128)` [source]_"
  },
  {
    "book_name": "suppress-healthchecks.html",
    "abstract": "介绍了如何通过注册和加载设置配置文件来全局禁用特定的 Hypothesis 健康检查（HealthCheck），并说明了本地设置会覆盖全局配置。",
    "content": "Suppress a health check everywhere\n==================================\n\nHypothesis sometimes raises a `HealthCheck` to indicate that your test may be less effective than you expect, slower than you expect, unlikely to generate effective examples, or otherwise has silently degraded performance.\n\nWhile `HealthCheck` can be useful to proactively identify issues, you may not care about certain classes of them. If you want to disable a `HealthCheck` everywhere, you can register and load a settings profile with `register_profile()` and `load_profile()`. Place the following code in any file which is loaded before running your tests (or in `conftest.py`, if using pytest):\n\n```python\nfrom hypothesis import HealthCheck, settings\nsettings.register_profile(\n    \"my_profile\", suppress_health_check=[HealthCheck.filter_too_much]\n)\nsettings.load_profile(\"my_profile\")\n```\n\nThis profile in particular suppresses the `HealthCheck.filter_too_much` health check for all tests. The exception is if a test has a `@settings` which explicitly sets a different value for `suppress_health_check`, in which case the profile value will be overridden by the local settings value."
  },
  {
    "book_name": "suppress-healthchecks.html",
    "abstract": "文章开头强调应谨慎抑制健康检查，并提供了全局抑制所有健康检查的代码示例。",
    "content": "\n\nI want to suppress all health checks!\n=====================================\n\n**Warning:** We strongly recommend that you suppress health checks as you encounter them, rather than using a blanket suppression. Several health checks check for subtle interactions that may save you hours of debugging, such as `HealthCheck.function_scoped_fixture` and `HealthCheck.differing_executors`.\n\nIf you really want to suppress all health checks, for instance to speed up interactive prototyping, you can:\n\n```python\nfrom hypothesis import HealthCheck, settings\nsettings.register_profile(\"my_profile\", suppress_health_check=list(HealthCheck))\nsettings.load_profile(\"my_profile\")"
  },
  {
    "book_name": "type-strategies.html",
    "abstract": "介绍了如何为 Hypothesis 策略（strategies）编写类型提示，包括使用 SearchStrategy[T] 作为返回策略的函数的返回类型，并通过代码示例展示了基本用法。",
    "content": "Write type hints for strategies\n================================\n\nHypothesis provides type hints for all strategies and functions which return a strategy:\n\n```python\nfrom hypothesis import strategies as st\nreveal_type(st.integers())\n# SearchStrategy[int]\nreveal_type(st.lists(st.integers()))\n# SearchStrategy[list[int]]\n```\n\n`SearchStrategy` is the type of a strategy. It is parametrized by the type of the example it generates. You can use it to write type hints for your functions which return a strategy:"
  },
  {
    "book_name": "type-strategies.html",
    "abstract": "通过代码示例详细说明了如何为返回数值策略的函数编写类型提示，并阐明了策略本身（SearchStrategy[int]）与返回策略的函数（Callable[..., SearchStrategy[int]]）之间的类型区别。",
    "content": "\n\n```python\nfrom hypothesis import strategies as st\nfrom hypothesis.strategies import SearchStrategy\n\n# returns a strategy for \"normal\" numbers\ndef numbers() -> SearchStrategy[int | float]:\n    return st.integers() | st.floats(allow_nan=False, allow_infinity=False)\n```\n\nIt’s worth pointing out the distinction between a strategy, and a function that returns a strategy. `integers()` is a function which returns a strategy, and that strategy has type `SearchStrategy[int]`. The function `st.integers` therefore has type `Callable[..., SearchStrategy[int]]`, while the value `s = st.integers()` has type `SearchStrategy[int]`."
  },
  {
    "book_name": "type-strategies.html",
    "abstract": "说明了在使用 @composite 装饰器定义策略时，其类型提示应直接使用该策略生成值的类型（如 tuple[int, int]），而不是 SearchStrategy。",
    "content": "\n\nType hints for `@composite`\n---------------------------\n\nWhen writing type hints for strategies defined with `@composite`, use the type of the returned value (not `SearchStrategy`):\n\n```python\n@st.composite\ndef ordered_pairs(draw) -> tuple[int, int]:\n    n1 = draw(st.integers())\n    n2 = draw(st.integers(min_value=n1))\n    return (n1, n2)"
  },
  {
    "book_name": "type-strategies.html",
    "abstract": "解释了 SearchStrategy 的协变（covariant）特性，即如果类型 B 是 A 的子类型，那么 SearchStrategy[B] 也是 SearchStrategy[A] 的子类型，并用 Dog 和 Animal 的例子进行了说明。",
    "content": "\n```\n\nType variance of `SearchStrategy`\n--------------------------------\n\n`SearchStrategy` is covariant, meaning that if `B < A` then `SearchStrategy[B] < SearchStrategy[A]`. In other words, the strategy `st.from_type(Dog)` is a subtype of the strategy `st.from_type(Animal)`."
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "介绍如何通过 .map() 方法对策略进行简单转换，例如将整数列表生成策略转换为有序列表生成策略。",
    "content": "Adapting strategies\n===================\n\nThis page discusses ways to adapt strategies to your needs, either by transforming them inline with `.map()`, or filtering out unwanted inputs with `.filter()` and `assume()`.\n\nMapping strategy inputs\n-----------------------\n\nSometimes you want to apply a simple transformation to a strategy. For instance, we know that we can generate lists of integers with `lists(integers())`. But maybe we wanted to instead generate sorted lists. We could use an inline `.map()` to achieve this:\n\nIn general, `strategy.map(f)` returns a new strategy which transforms all the examples generated by `strategy` by calling `f` on them."
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "介绍了Hypothesis库中使用.filter()方法来过滤策略生成的输入，以排除不满足条件的测试用例，例如通过过滤掉零值来避免模运算中的ZeroDivisionError。",
    "content": "\n\nFiltering strategy inputs\n-------------------------\n\nMany strategies in Hypothesis offer some control over the kinds of values that get generated. For instance, `integers(min_value=0)` generates positive integers, and `integers(100, 200)` generates integers between 100 and 200.\n\nSometimes, you need more control than this. The inputs from a strategy may not match exactly what you need, and you just need to filter out a few bad cases.\n\nFor instance, suppose we have written a simple test involving the modulo operator `%`:\n\n```python\nfrom hypothesis import given, strategies as st\n\n@given(st.integers(), st.integers())\ndef test_remainder_magnitude(a, b):\n    # the remainder after division is always less than\n    # the divisor\n    assert abs(a % b) < abs(b)\n```\n\nHypothesis will quickly report a failure for this test: `ZeroDivisionError: integer modulo by zero`. Just like division, modulo isn’t defined for 0. The case of `b == 0` isn’t interesting for the test, and we would like to get rid of it.\n\nThe best way to do this is with the `.filter()` method:\n\n```python\nfrom hypothesis import assume, given, strategies as st\n\n@given(st.integers(), st.integers().filter(lambda n: n != 0))\ndef test_remainder_magnitude(a, b):\n    # b is guaranteed to be nonzero here, thanks to the filter\n    assert abs(a % b) < abs(b)\n```\n\nThis test now"
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "介绍了Hypothesis库中用于筛选测试输入的两种方法：`.filter()`和`assume()`。`.filter()`作用于单个策略，而`assume()`可用于基于任意条件跳过整个测试用例。",
    "content": " passes cleanly.\n\nCalling `.filter()` on a strategy creates a new strategy with that filter applied at generation-time. For instance, `integers().filter(lambda n: n != 0)` is a strategy which generates nonzero integers.\n\nAssuming away test cases\n------------------------\n\n`.filter()` lets you filter test inputs from a single strategy. Hypothesis also provides an `assume()` function for when you need"
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "介绍了Hypothesis库中`assume()`函数的用途，它可以根据任意条件跳过测试用例，并通过一个检查取余运算结果绝对值的示例展示了其用法。",
    "content": " to filter an entire test case, based on an arbitrary condition.\n\nThe `assume()` function skips test cases where some condition evaluates to `True`. You can use it anywhere in your test. We could have expressed our `.filter()` example above using `assume()` as well:\n\n```python\nfrom hypothesis import assume, given, strategies as st\n\n@given(st.integers(), st.integers())\ndef test_remainder_magnitude(a, b):\n    assume(b != 0)\n    # b will be nonzero here\n    assert abs(a % b) < abs(b)"
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "对比了`assume()`和`.filter()`的使用场景，建议优先使用`.filter()`以获得更高效的采样，并指出对于无法用`.filter()`表达的复杂关系应使用`assume()`。",
    "content": "\n```\n\n`assume()` vs `.filter()`\n-------------------------\n\nWhere possible, you should use `.filter()`. Hypothesis can often rewrite simple filters into more efficient sampling methods than rejection sampling, and will retry filters several times instead of aborting the entire test case (as with `assume()`).\n\nFor more complex relationships that can’t be expressed with `.filter()`, use `assume()`."
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "(part 1/2) 通过一个关于整除运算的测试用例，展示了如何结合使用`assume()`和`.filter()`来处理多个过滤条件，将简单的非零条件用`.filter()`实现。",
    "content": "\n\nHere’s an example of a test where we want to filter out two different types of examples:\n\n```python\nfrom hypothesis import assume, given, strategies as st\n\n@given(st.integers(), st.integers())\ndef test_floor_division_lossless_when_b_divides_a(a, b):\n    # we want to assume that:\n    # * b is nonzero, and\n    # * b divides a\n    assert (a // b) * b == a"
  },
  {
    "book_name": "adapting-strategies.html",
    "abstract": "(part 2/2) 说明了复杂的`a % b == 0`条件必须保留为`assume()`，因为它表达了`a`和`b`之间更复杂的关系。",
    "content": "\n```\n\nWe could start by using `assume()` for both:\n\n```python\nfrom hypothesis import assume, given, strategies as st\n\n@given(st.integers(), st.integers())\ndef test_floor_division_lossless_when_b_divides_a(a, b):\n    assume(b != 0)\n    assume(a % b == 0)\n    assert (a // b) * b == a\n```\n\nAnd then notice that the `b != 0` condition can be moved into the strategy definition as a `.filter()` call:\n\n```python\nfrom hypothesis import assume, given, strategies as st\n\n@given(st.integers(), st.integers().filter(lambda n: n != 0))\ndef test_floor_division_lossless_when_b_divides_a(a, b):\n    assume(a % b == 0)\n    assert (a // b) * b == a\n```\n\nHowever, the `a % b == 0` condition has to stay as an `assume()`, because it expresses a more complicated relationship between `a` and `b`."
  },
  {
    "book_name": "adding-notes.html",
    "abstract": "介绍了 Hypothesis 库中用于在测试失败时添加额外调试信息的 `note()` 函数，并通过一个打乱列表顺序的测试用例展示了其用法。同时简要提及了功能类似的 `event()` 函数，后者用于统计测试用例中的特定事件。",
    "content": "# Adding notes\n\nWhen a test fails, Hypothesis will normally print output that looks like this:\n\n```\nFalsifying example: test_a_thing(x=1, y=\"foo\")\n```\n\nSometimes you want to add some additional information to a failure, such as the output of some intermediate step in your test. The `note()` function lets you do this:\n\n```python\n>>> from hypothesis import given, note, strategies as st\n>>> @given(st.lists(st.integers()), st.randoms())\n... def test_shuffle_is_noop(ls, r):\n...     ls2 = list(ls)\n...     r.shuffle(ls2)\n...     note(f\"Shuffle: {ls2!r}\")\n...     assert ls == ls2\n...\n>>> try:\n...     test_shuffle_is_noop()\n... except AssertionError:\n...     print(\"ls != ls2\")\n...\nFalsifying example: test_shuffle_is_noop(ls=[0, 1], r=RandomWithSeed(1))\nShuffle: [1, 0]\nls != ls2\n```\n\n`note()` is like a print statement that gets attached to the falsifying example reported by Hypothesis. It’s also reported by observability, and shown for all examples (if `settings.verbosity` is set to `Verbosity.verbose` or higher).\n\n`event()` is a similar function which tells Hypothesis to count the number of test cases which reported each distinct value you pass, for inclusion in test statistics and observability reports."
  },
  {
    "book_name": "api.html",
    "abstract": "(part 1/2) 介绍了Hypothesis库中`@given`装饰器的基本用法，包括其作为主要入口点将函数转换为测试的功能，并详细说明了其参数可以是位置参数或关键字参数，以及相关的使用规则和示例。",
    "content": "# API Reference\n\nReference for non-strategy objects that are part of the Hypothesis API. For documentation on strategies, see the strategies reference.\n\n## `@given`\n\n- `hypothesis.given(*_given_arguments, **_given_kwargs)` [source]\n\nThe `@given` decorator turns a function into a Hypothesis test. This is the main entry point to Hypothesis.\n\nSee also the [Introduction to Hypothesis tutorial](#), which introduces defining Hypothesis tests with `@given`.\n\n### Arguments to `@given`\n\nArguments to `@given` may be either positional or keyword arguments:\n\n```python\n@given(st.integers(), st.floats())\ndef test_one(x, y):\n    pass\n\n@given(x=st.integers(), y=st.floats())\ndef test_two(x, y):\n    pass\n```\n\nIf using keyword arguments, the arguments may appear in any order, as with standard Python functions:\n\n```python\n# different order, but still equivalent to before\n@given(y=st.floats(), x=st.integers())\ndef test(x, y):\n    assert isinstance(x, int)\n    assert isinstance(y, float)\n```\n\nIf `@given` is provided fewer positional arguments than the decorated test, the test arguments are filled in on the right side, leaving the leftmost positional arguments unfilled:\n\n```python\n@given(st.integers(), st.floats())\ndef test(manual_string, y, z):\n    assert manual_string == \"x\"\n    assert isinstance(y, int)\n    assert isinstance(z, float)\n\n# `test` is now a callable which takes one argument `manual_string`\ntest(\"x\")  # or equivalently: test(manual_string=\"x\")\n```\n\nThe reason for this “from the right” behavior is to support using `@given` with instance methods, by automatically passing through `self`:\n\n```python\nclass MyTest(TestCase):\n    @given(st.integers())\n    def test(self, x):\n        assert isinstance(self, MyTest)\n        assert isinstance(x, int)\n```\n\nIf (and only if) using keyword arguments, `@given` may be combined with `**kwargs` or `*args`.\n\nIt is an error to:"
  },
  {
    "book_name": "api.html",
    "abstract": "(part 2/2) 继续介绍`@given`装饰器的使用限制，并引入了`hypothesis.infer`（即`...`）的概念，用于从类型注解推断策略。同时解释了`builds()`和`@given`在策略推断上的不同行为及各自的限制。",
    "content": "\n- Mix positional and keyword arguments to `@given`.\n- Use `@given` with a function that has a default value for an argument.\n- Use `@given` with positional arguments with a function that uses `*args`, `**kwargs`, or keyword-only arguments.\n\nThe function returned by `given` has all the same arguments as the original test, minus those that are filled in by `@given`. See the notes on framework compatibility for how this interacts with features of other testing libraries, such as pytest fixtures.\n\n## `hypothesis.infer`\n\nAn alias for `...` (`Ellipsis`). `infer` can be passed to `@given` or `builds()` to indicate that a strategy for that parameter should be inferred from its type annotations.\n\nIn all cases, using `infer` is equivalent to using `...`.\n\n### Inferred strategies\n\nIn some cases, Hypothesis can work out what to do when you omit arguments. This is based on introspection, not magic, and therefore has well-defined limits.\n\n`builds()` will check the signature of the target (using `inspect.signature()`). If there are required arguments with type annotations and no strategy was passed to `builds()`, `from_type()` is used to fill them in. You can also pass the value `...` (`Ellipsis`) as a keyword argument, to force this inference for arguments with a default value.\n\n`@given` does not perform any implicit inference for required arguments, as this would break compatibility with pytest fixtures. `...` (`Ellipsis`), can be used as a keyword argument to explicitly fill in an argument from its type annotation. You can also use the `infer` alias if writing a literal `...` seems too weird.\n\n`@given(...)` can also be specified to fill all arguments from their type annotations.\n\n### Limitations\n\nHypo"
  }
]